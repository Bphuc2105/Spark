# src/train.py

from pyspark.ml import Pipeline
# Import a regression model, e.g., LinearRegression or RandomForestRegressor
from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor
from pyspark.ml.evaluation import RegressionEvaluator # Changed from BinaryClassificationEvaluator
from pyspark.sql.functions import col



def train_regression_model(spark, training_data_df, preprocessing_pipeline_stages):
    """
    Huấn luyện mô hình hồi quy sử dụng pipeline tiền xử lý và dữ liệu huấn luyện.

    Args:
        spark (SparkSession): Đối tượng SparkSession.
        training_data_df (DataFrame): DataFrame chứa dữ liệu đã được join (giá và bài báo).
                                      Cần có cột 'open_price', 'close_price', 'full_article_text'.
                                      The 'label' for regression (e.g., next day's 'close_price' or price change)
                                      is assumed to be generated by the preprocessing_pipeline.
        preprocessing_pipeline_stages (list): Danh sách các stage của pipeline tiền xử lý
                                              (từ create_preprocessing_pipeline).

    Returns:
        pyspark.ml.PipelineModel: Mô hình Pipeline đã được huấn luyện.
                                  Trả về None nếu có lỗi.
    """
    if training_data_df is None:
        print("Dữ liệu huấn luyện là None. Không thể huấn luyện mô hình.")
        return None

    try:
        # --- 1. Chuẩn bị dữ liệu huấn luyện và kiểm tra ---
        # Loại bỏ các hàng có giá trị null trong các cột quan trọng
        # Cột 'close_price' (hoặc target variable) cần thiết cho SQLTransformer (trong preprocessing_pipeline) để tạo nhãn.
        # 'full_article_text' và 'open_price' là các feature đầu vào.
        # Ensure the 'label' column (target for regression) is also checked if it's derived from columns that might be null.
        # For this example, we assume 'label' is created correctly by the preprocessing pipeline.
        # If 'label' is 'close_price', it's already in columns_to_check_null.
        columns_to_check_null = ["full_article_text", "open_price", "close_price"] # Add other columns if they are used to create the label
        cleaned_df = training_data_df.na.drop(subset=columns_to_check_null)

        if cleaned_df.count() == 0:
            print("Không có dữ liệu huấn luyện sau khi loại bỏ các hàng null.")
            return None

        print(f"Số lượng mẫu sau khi làm sạch null để huấn luyện: {cleaned_df.count()}")

        # Chia dữ liệu thành tập huấn luyện và tập kiểm tra
        (train_df, test_df) = cleaned_df.randomSplit([0.8, 0.2], seed=42)
        print(f"Số lượng mẫu huấn luyện: {train_df.count()}")
        print(f"Số lượng mẫu kiểm tra: {test_df.count()}")

        # --- 2. Định nghĩa mô hình học máy (Hồi quy) ---
        # Cột nhãn đã được tạo bởi SQLTransformer trong preprocessing_pipeline (tên là 'label')
        # Cột đặc trưng đã được tạo bởi VectorAssembler (tên là 'features')

        # Ví dụ sử dụng Linear Regression
        lr_regressor = LinearRegression(featuresCol="features", labelCol="label", predictionCol="prediction")

        # Hoặc bạn có thể thử RandomForestRegressor
        # rf_regressor = RandomForestRegressor(featuresCol="features", labelCol="label", predictionCol="prediction", numTrees=100)

        # Hoặc GBTRegressor
        # gbt_regressor = GBTRegressor(featuresCol="features", labelCol="label", predictionCol="prediction", maxIter=10)

        # Chọn một mô hình để sử dụng:
        model_to_use = lr_regressor # Change this to rf_regressor or gbt_regressor if you want to try others

        # --- 3. Tạo Pipeline hoàn chỉnh ---
        full_pipeline = Pipeline(stages=preprocessing_pipeline_stages + [model_to_use])

        # --- 4. Huấn luyện Pipeline ---
        print("\nBắt đầu huấn luyện pipeline hồi quy hoàn chỉnh...")
        pipeline_model = full_pipeline.fit(train_df)
        print("Huấn luyện pipeline hoàn tất.")

        # --- 5. Đánh giá mô hình trên tập kiểm tra ---
        print("\nĐánh giá mô hình trên tập kiểm tra...")
        predictions_df = pipeline_model.transform(test_df)

        # Hiển thị một vài dự đoán
        print("\nMột vài dự đoán trên tập kiểm tra:")
        # rawPrediction and probability are typically for classification, 'prediction' is the output for regression.
        predictions_df.select("date", "symbol", "open_price", "close_price", "full_article_text", "label", "prediction").show(10, truncate=True)

        # Sử dụng RegressionEvaluator để đánh giá
        evaluator_rmse = RegressionEvaluator(labelCol="label", predictionCol="prediction", metricName="rmse")
        rmse = evaluator_rmse.evaluate(predictions_df)
        print(f"Root Mean Squared Error (RMSE) trên tập kiểm tra: {rmse:.4f}")

        evaluator_mse = RegressionEvaluator(labelCol="label", predictionCol="prediction", metricName="mse")
        mse = evaluator_mse.evaluate(predictions_df)
        print(f"Mean Squared Error (MSE) trên tập kiểm tra: {mse:.4f}")

        evaluator_r2 = RegressionEvaluator(labelCol="label", predictionCol="prediction", metricName="r2")
        r2 = evaluator_r2.evaluate(predictions_df)
        print(f"R-squared (R2) trên tập kiểm tra: {r2:.4f}")

        evaluator_mae = RegressionEvaluator(labelCol="label", predictionCol="prediction", metricName="mae")
        mae = evaluator_mae.evaluate(predictions_df)
        print(f"Mean Absolute Error (MAE) trên tập kiểm tra: {mae:.4f}")

        return pipeline_model

    except Exception as e:
        print(f"Lỗi trong quá trình huấn luyện mô hình hồi quy: {e}")
        import traceback
        traceback.print_exc()
        return None

def save_model(model, path):
    """
    Lưu PipelineModel đã huấn luyện.

    Args:
        model (PipelineModel): Mô hình PipelineModel cần lưu.
        path (str): Đường dẫn để lưu mô hình.
    """
    if model is None:
        print("Mô hình là None. Không thể lưu.")
        return
    try:
        print(f"\nĐang lưu mô hình vào: {path}")
        model.write().overwrite().save(path) # overwrite() để ghi đè nếu đã tồn tại
        print("Lưu mô hình thành công.")
    except Exception as e:
        print(f"Lỗi khi lưu mô hình: {e}")

if __name__ == "__main__":
    # Import các module cần thiết từ project
    from data_loader_testing import get_spark_session, load_stock_prices, load_news_articles, join_data
    from preprocessing import create_preprocessing_pipeline # Sử dụng pipeline đã tạo

    # Các hàm khác sẽ cần được định nghĩa hoặc import đúng cách
    spark = get_spark_session(app_name="StockPrediction_Regression_Train")

# --- Cấu hình đường dẫn (giống như trong data_loader.py) ---
    prices_path = "data/prices.csv"
    articles_path =  "data/articles.csv"
    model_output_path = "models/stock_prediction_regression_pipeline_model" # Changed path name

    # --- Tải dữ liệu ---
    prices_df = load_stock_prices(spark, prices_path)
    articles_df = load_news_articles(spark, articles_path)

    if prices_df and articles_df:
        # Kết hợp dữ liệu
        # Hàm join_data từ data_loader.py sẽ tạo cột 'full_article_text'
        raw_joined_df = join_data(prices_df, articles_df)
        if raw_joined_df:
            print("\nDữ liệu đã join để huấn luyện:")
            raw_joined_df.printSchema()
            raw_joined_df.show(5, truncate=True)

            # --- Tạo pipeline tiền xử lý ---
            # QUAN TRỌNG: Đảm bảo 'output_label_col' trong 'create_preprocessing_pipeline'
            # tạo ra một cột nhãn SỐ LIÊN TỤC phù hợp cho hồi quy.
            # Ví dụ: nếu bạn muốn dự đoán giá đóng cửa tiếp theo, 'label' phải là giá đó.
            # Điều này thường được định nghĩa trong SQLTransformer bên trong create_preprocessing_pipeline.
            # Ví dụ, nếu 'label' là 'close_price' (để dự đoán giá đóng cửa hiện tại dựa trên tin tức và giá mở cửa)
            # hoặc một giá trị tính toán như 'next_day_close_price'.
            #
            # Giả sử create_preprocessing_pipeline được điều chỉnh để tạo ra một 'label' là 'close_price'
            # (hoặc một giá trị số liên tục khác cho mục tiêu hồi quy).
            # Ví dụ, trong SQLTransformer của bạn, thay vì "CASE WHEN close_price > open_price THEN 1.0 ELSE 0.0 END AS label",
            # bạn có thể có "close_price AS label" hoặc "close_price - open_price AS label_price_change".
            preprocessing_pipeline_obj = create_preprocessing_pipeline(
                text_input_col="full_article_text",
                numerical_input_cols=["open_price"], # 'close_price' is now the target (label)
                                                      # or if predicting price change, it might still be used as input.
                                                      # This depends on how you define your label in preprocessing.
                output_features_col="features",
                output_label_col="label" # Ensure this 'label' IS THE REGRESSION TARGET (e.g., actual 'close_price')
            )
            
            preprocessing_stages = preprocessing_pipeline_obj.getStages()

            # --- Huấn luyện mô hình hồi quy ---
            trained_pipeline_model = train_regression_model(spark, raw_joined_df, preprocessing_stages)

            if trained_pipeline_model:
                save_model(trained_pipeline_model, model_output_path)
            else:
                print("Huấn luyện mô hình hồi quy thất bại. Không có mô hình để lưu.")
        else:
            print("Không thể join dữ liệu huấn luyện.")
    else:
        print("Không thể tải dữ liệu giá hoặc bài báo để huấn luyện.")

    spark.stop()